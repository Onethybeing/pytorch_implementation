{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNP7H24jjtttLLTh1GPRwvj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Onethybeing/pytorch_implementation/blob/main/FCN8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "p4GT48eEscM5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as model\n",
        "vgg = model.vgg16(pretrained= True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSO3JWb8sstD",
        "outputId": "4bfc3c4e-fcb9-43b8-c9cc-6e3e973a2433"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pool 3\n",
        "#pool 4\n",
        "#final-output\n",
        "from torchsummary import summary\n",
        "summary(vgg,(3,244,244))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHEsrWlns1A_",
        "outputId": "692a2dc7-0336-4195-9943-3135a4129bbc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 244, 244]           1,792\n",
            "              ReLU-2         [-1, 64, 244, 244]               0\n",
            "            Conv2d-3         [-1, 64, 244, 244]          36,928\n",
            "              ReLU-4         [-1, 64, 244, 244]               0\n",
            "         MaxPool2d-5         [-1, 64, 122, 122]               0\n",
            "            Conv2d-6        [-1, 128, 122, 122]          73,856\n",
            "              ReLU-7        [-1, 128, 122, 122]               0\n",
            "            Conv2d-8        [-1, 128, 122, 122]         147,584\n",
            "              ReLU-9        [-1, 128, 122, 122]               0\n",
            "        MaxPool2d-10          [-1, 128, 61, 61]               0\n",
            "           Conv2d-11          [-1, 256, 61, 61]         295,168\n",
            "             ReLU-12          [-1, 256, 61, 61]               0\n",
            "           Conv2d-13          [-1, 256, 61, 61]         590,080\n",
            "             ReLU-14          [-1, 256, 61, 61]               0\n",
            "           Conv2d-15          [-1, 256, 61, 61]         590,080\n",
            "             ReLU-16          [-1, 256, 61, 61]               0\n",
            "        MaxPool2d-17          [-1, 256, 30, 30]               0\n",
            "           Conv2d-18          [-1, 512, 30, 30]       1,180,160\n",
            "             ReLU-19          [-1, 512, 30, 30]               0\n",
            "           Conv2d-20          [-1, 512, 30, 30]       2,359,808\n",
            "             ReLU-21          [-1, 512, 30, 30]               0\n",
            "           Conv2d-22          [-1, 512, 30, 30]       2,359,808\n",
            "             ReLU-23          [-1, 512, 30, 30]               0\n",
            "        MaxPool2d-24          [-1, 512, 15, 15]               0\n",
            "           Conv2d-25          [-1, 512, 15, 15]       2,359,808\n",
            "             ReLU-26          [-1, 512, 15, 15]               0\n",
            "           Conv2d-27          [-1, 512, 15, 15]       2,359,808\n",
            "             ReLU-28          [-1, 512, 15, 15]               0\n",
            "           Conv2d-29          [-1, 512, 15, 15]       2,359,808\n",
            "             ReLU-30          [-1, 512, 15, 15]               0\n",
            "        MaxPool2d-31            [-1, 512, 7, 7]               0\n",
            "AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0\n",
            "           Linear-33                 [-1, 4096]     102,764,544\n",
            "             ReLU-34                 [-1, 4096]               0\n",
            "          Dropout-35                 [-1, 4096]               0\n",
            "           Linear-36                 [-1, 4096]      16,781,312\n",
            "             ReLU-37                 [-1, 4096]               0\n",
            "          Dropout-38                 [-1, 4096]               0\n",
            "           Linear-39                 [-1, 1000]       4,097,000\n",
            "================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.68\n",
            "Forward/backward pass size (MB): 258.51\n",
            "Params size (MB): 527.79\n",
            "Estimated Total Size (MB): 786.98\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision import models\n",
        "\n",
        "class FCN8(nn.Module):\n",
        "  def __init__(self,num_classes=2):\n",
        "    super(FCN8,self).__init__()\n",
        "    vgg = models.vgg16(pretrained= True)\n",
        "    self.features = vgg.features #find the feature map\n",
        "    #extract intermediate feature map\n",
        "    self.pool3 = self.features[:17]\n",
        "    self.pool4 = self.features[:24]\n",
        "    self.pool5 = self.features\n",
        "    #1x1 convolutions to convert to class scores\n",
        "    self.conv1x1_3 = nn.Conv2d(256,num_classes,1)\n",
        "    self.conv1x1_4 = nn.Conv2d(512,num_classes,1)\n",
        "    self.conv1x1_5 = nn.Conv2d(512,num_classes,1)\n",
        "    self.upsample32 = nn.ConvTranspose2d(num_classes,num_classes,kernel_size=4,stride=2,padding =1)#2 times\n",
        "    self.upsample16 = nn.ConvTranspose2d(num_classes,num_classes,kernel_size=4,stride=2,padding =1)#2 times\n",
        "    self.upsample8 = nn.ConvTranspose2d(num_classes,num_classes,kernel_size=16,stride=8,padding =4)#8 times\n",
        "\n",
        "  def forward(self,x):\n",
        "    pool3_out = self.pool3(x)\n",
        "    pool4_out = self.pool4(x)\n",
        "    pool5_out = self.pool5(x)\n",
        "    conv1x1_3_out = self.conv1x1_3(pool3_out)\n",
        "    conv1x1_4_out = self.conv1x1_4(pool4_out)\n",
        "    conv1x1_5_out = self.conv1x1_5(pool5_out)\n",
        "    x = self.upsample32(conv1x1_5_out) + conv1x1_4_out\n",
        "    x = self.upsample16(x)+conv1x1_3_out\n",
        "    x = self.upsample8(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "qv3glC1CtX1E"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I= input size\n",
        "# S = stride\n",
        "# P = padding\n",
        "# K = kernel size\n",
        "# O = (I-1)*S+K-2*P"
      ],
      "metadata": {
        "id": "xxe1r0IAt6ZH"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FCN8(num_classes =2)\n",
        "dummy_input = torch.randn(1,3,224,224)\n",
        "output = model(dummy_input)\n",
        "print(\"Output shape: \",output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5CfT6m__Dcc",
        "outputId": "e9a9618f-01b9-4bde-a1eb-74da973f76ff"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape:  torch.Size([1, 2, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UKSPe6Kh_rR5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}